{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import  pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from training.networks import  define_G\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from training.model import * #Generator,Discriminator\n",
    "from training.model_unet import * #Generator,Discriminator\n",
    "from training.database import *\n",
    "from training.utils import *\n",
    "# from code.database import ImageDataset\n",
    "\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestOpts():\n",
    "    def __init__(self,seed=1234):\n",
    "        self.gan_name=\"cycle_paired\"\n",
    "\n",
    "        self.fix_seed(seed)\n",
    "        self.experience_ver=\"cyclegan_unpaired_ver5.1.0\"\n",
    "        # self.experience_ver=\"cyclegan_unpaired_ver1.0.0\"\n",
    "        # self.experience_ver=\"cyclegan_paired_ver1.0.0\"\n",
    "        self.version=\"0.0.0\"\n",
    "        self.start_epoch = 0\n",
    "        self.n_epochs = 1\n",
    "        self.batch_size = 1\n",
    "        self.dataroot = \"../dataset/SUNRGBD/SUNRGBD/kv1/b3dodata/\"\n",
    "        self.lr = 0.0002\n",
    "        self.decay_epoch = 200\n",
    "        self.size = (256,256)\n",
    "        self.domainA_nc = 3\n",
    "        self.domainB_nc = 3\n",
    "        self.cpu = False\n",
    "        self.n_cpu = 0\n",
    "        self.device_name = \"cuda:0\" #if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device =  torch.device(self.device_name) \n",
    "        self.load_weight = True\n",
    "        self.depth_name=\"depth_bfx\"\n",
    "\n",
    "    def fix_seed(self,seed):\n",
    "        # Numpy\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        # Pytorch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "opt=TestOpts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "\"\"\" --- Initial Setting  ---\"\"\"\n",
    "\n",
    "root_path=\"../output/\"\n",
    "model_path=root_path+f\"model/{opt.experience_ver}/netG_A2B.pth\"\n",
    "model_path_=root_path+f\"model/{opt.experience_ver}/netG_B2A.pth\"\n",
    "# model_path=r\"latest_net_G_A.pth\"\n",
    "# model_path_=r\"latest_net_G_B.pth\"\n",
    "record_path=root_path+f\"generate/{opt.experience_ver}/\"\n",
    "analysis_path=root_path+f\"analysis/{opt.experience_ver}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform( params=None, grayscale=None, method=Image.BICUBIC, convert=True):\n",
    "    transform_list = []\n",
    "    if grayscale:\n",
    "        transform_list.append(transforms.Grayscale(1))\n",
    "    \n",
    "    osize = [opt.load_size, opt.load_size]\n",
    "    transform_list.append(transforms.Resize(osize, method))\n",
    "    \n",
    "    transform_list.append(transforms.RandomCrop(256))\n",
    "    \n",
    "\n",
    "    # if not opt.no_flip:\n",
    "    #     if params is None:\n",
    "    #         transform_list.append(transforms.RandomHorizontalFlip())\n",
    "    #     elif params['flip']:\n",
    "    #         transform_list.append(transforms.Lambda(lambda img: __flip(img, params['flip'])))\n",
    "\n",
    "    if convert:\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "        if grayscale:\n",
    "            transform_list += [transforms.Normalize((0.5,), (0.5,))]\n",
    "        else:\n",
    "            transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disnorm(img):\n",
    "    IMAGENET_MEAN = [0.5, 0.5, 0.5]\n",
    "    IMAGENET_STD = [0.5, 0.5, 0.5]\n",
    "\n",
    "    return 0.5*(img + 1.0)\n",
    "def norm_im(im,cof=1):\n",
    "    return (im-np.min(im))/(np.max(im)-np.min(im))*cof\n",
    "\n",
    "def create_image(netG_A2B,net_B2A,input_A,input_B,batch,is_norm=False):\n",
    "        # Set model input\n",
    "        real_A = Variable(input_A.copy_(batch['A']))\n",
    "        # real_B = Variable(input_B.copy_(batch['B']))\n",
    "\n",
    "        # Generate output\n",
    "        # fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "        fake_B=tensor2im(netG_A2B(real_A))\n",
    "        cycle_A=tensor2im(netG_B2A(netG_A2B(real_A)))\n",
    "\n",
    "        # out_img1 = torch.cat([real_A, fake_B,real_B], dim=2)\n",
    "\n",
    "        A=tensor2im(real_A)\n",
    "        B=None#tensor2im(real_B)\n",
    "\n",
    "        if is_norm:\n",
    "            return A,B,norm_im(fake_B)\n",
    "        \n",
    "\n",
    "    \n",
    "        return A,B,fake_B,cycle_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "num dataloader= 554\n"
     ]
    }
   ],
   "source": [
    "\"\"\" --- Call Models ---\"\"\"\n",
    "\n",
    "\n",
    "# 生成器\n",
    "# netG_A2B = Generator(opt.domainA_nc, opt.domainB_nc)\n",
    "netG_A2B=define_G(input_nc=3,output_nc=1,ngf=64,netG='resnet_9blocks')\n",
    "netG_B2A=define_G(input_nc=1,output_nc=3,ngf=64,netG='resnet_9blocks')\n",
    "# GPU\n",
    "if not opt.cpu:\n",
    "    netG_A2B.cuda()\n",
    "    netG_B2A.cuda()\n",
    "\n",
    "# 重みパラメータ初期化\n",
    "# netG_A2B.apply(weights_init_normal)\n",
    "\n",
    "# 保存したモデルのロード\n",
    "# state_dict = torch.load(model_path, map_location=\"cuda:0\")\n",
    "# if hasattr(state_dict, '_metadata'):\n",
    "#     del state_dict._metadata\n",
    "# for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
    "#     __patch_instance_norm_state_dict(state_dict, netG_A2B, key.split('.'))\n",
    "# netG_A2B.load_state_dict(state_dict)\n",
    "\n",
    "netG_A2B.load_state_dict(torch.load(model_path, map_location=\"cuda:0\"), strict=False)\n",
    "netG_B2A.load_state_dict(torch.load(model_path_, map_location=\"cuda:0\"), strict=False)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "# 入出力メモリ確保\n",
    "Tensor = torch.cuda.FloatTensor if not opt.cpu else torch.Tensor\n",
    "input_A = Tensor(opt.batch_size, opt.domainA_nc, opt.size[1], opt.size[0])\n",
    "input_B = Tensor(opt.batch_size, opt.domainB_nc, opt.size[1], opt.size[0])\n",
    "target_real = Variable(Tensor(opt.batch_size).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(opt.batch_size).fill_(0.0), requires_grad=False)\n",
    "\n",
    "# 過去データ分のメモリ確保\n",
    "# データローダー\n",
    "transforms_ = [ \n",
    "                transforms.Resize((int(opt.size[0]),int(opt.size[1])), Image.BICUBIC), \n",
    "                # transforms.RandomCrop(opt.size), \n",
    "                # transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)) \n",
    "                ]\n",
    "\n",
    "dataset=ImageDataset(opt,root=opt.dataroot, unaligned=False,limit=None)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n",
    "\n",
    "#Dataset for sampling \n",
    "sample_images=[dataset[i] for i in range(100) ]\n",
    "\n",
    "print(\"num dataloader= {}\".format(len(dataloader)))\n",
    "\n",
    "#Release Memory\n",
    "# del netD_A,netD_B,fake_A_buffer,fake_B_buffer\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "#Save generate image from netG\n",
    "images=create_image(netG_A2B,netG_B2A,input_A,input_B,sample_images[0])\n",
    "\n",
    "# mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 554/554 [00:53<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "results={\"color\":[],\"depth\":[],\"fake\":[]}\n",
    "folders=os.listdir(opt.dataroot)\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    batch=dataset[i]\n",
    "    _save_path=f\"{opt.dataroot}{folders[i]}/{opt.gan_name}/\"\n",
    "    if not os.path.exists(_save_path):\n",
    "        os.mkdir(_save_path)\n",
    "    else:\n",
    "        shutil.rmtree(_save_path)\n",
    "        os.mkdir(_save_path)\n",
    "    imgs=create_image(netG_A2B,netG_B2A,input_A,input_B,batch)\n",
    "    cv2.imwrite(f\"{_save_path}fake_{i}.png\",imgs[2])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUNRGBD/kv2/kinect2data/000002_2014-05-26_14-23-37_260595134347_rgbf000103-resize'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes=np.loadtxt(r\"..\\dataset\\SUNRGBD\\SUNRGBD\\kv2\\kinect2data_segmentation\\test_images_path.txt\",dtype=str)\n",
    "pathes[0][:pathes[0].rfind(\"/image\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5050/5050 [07:33<00:00, 11.14it/s]\n"
     ]
    }
   ],
   "source": [
    "results={\"color\":[],\"depth\":[],\"fake\":[]}\n",
    "trans= transforms.Compose(transforms_)\n",
    "for i in tqdm(range(len(pathes))):\n",
    "    _p=\"../dataset/SUNRGBD/\"+pathes[i]\n",
    "    # batch=dataset[i]\n",
    "    color=trans(Image.open(_p).convert('RGB'))\n",
    "    _r=pathes[i][:pathes[i].rfind(\"/image\")]\n",
    "    _save_path=f\"../dataset/SUNRGBD/{_r}/{opt.gan_name}/\"\n",
    "    if not os.path.exists(_save_path):\n",
    "        os.mkdir(_save_path)\n",
    "    imgs=create_image(netG_A2B,netG_B2A,input_A,input_B,{\"A\":color,\"B\":None})\n",
    "    cv2.imwrite(f\"{_save_path}fake_{i}.png\",imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46582408b89589d3bd3d12d321c2cb6c6e45aa316cb99208fb6329a382c56ac7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('jupyter': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
